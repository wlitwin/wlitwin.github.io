Here's the compilation pipeline:

```
  Source string
      │
      ▼
  ┌──────────┐
  │ 1. LEXER │  lib/lexer.ml
  │          │  string → Token.token list
  └────┬─────┘
       │
       ▼
  ┌───────────┐
  │ 2. PARSER │  lib/parser.ml
  │           │  token list → Ast.program (= Ast.decl list)
  └────┬──────┘
       │
       ▼
  ┌────────────────┐
  │ 3. TYPECHECKER │  lib/typechecker.ml
  │                │  Ast.program → tprogram (= tdecl list of texpr)
  │  3a. synth/    │  Hindley-Milner inference with unification
  │      check     │  Attaches Types.ty to every node
  │                │
  │  3b. fundep    │  improve_fundeps_in_expr (before generalize)
  │      improve   │  apply_fundep_improvement (whole-program post-pass)
  │                │
  │  3c. transform │  transform_constraints
  │      constraints│  Rewrites typeclass calls → dictionary field accesses
  └────┬───────────┘
       │
       ▼
  ┌──────────────┐
  │ 4. COMPILER  │  lib/compiler.ml
  │              │  tprogram → Bytecode.compiled_program
  │              │  Walks texpr, emits stack-based bytecode
  └────┬─────────┘
       │
       ▼
  ┌──────────────┐
  │ 4b.OPTIMIZER │  lib/optimize.ml
  │              │  Bytecode peephole optimization
  │              │  Dead code, superinstructions, etc.
  └────┬─────────┘
       │
       ▼
  ┌──────────────┐
  │ 5. VM        │  lib/vm.ml
  │              │  compiled_program → Bytecode.value
  │              │  Stack-based, 81 opcodes, tail-call opt
  └──────────────┘
```

  Key IRs:

- Ast.expr — untyped, sugar included (EFor, EAnnot, etc.)
- texpr — typed, desugared (every node has ty: Types.ty), constraints transformed to explicit dict passing
- Bytecode.opcode — stack-based instructions (CONST, ADD, CALL, CLOSURE, JUMP_IF_FALSE, etc.)

## Optimization Passes

After stage 4 (compilation), the bytecode goes through a peephole optimizer (`lib/optimize.ml`) before being serialized or executed. The optimizer is enabled by default and can be disabled with `--no-optimize` in the self-hosted compiler or via the "Optimize" checkbox in the web playground.

The optimizer uses a three-phase architecture:

1. **Mark** — Scan the bytecode linearly, tagging each instruction as `Keep`, `Remove`, or `ReplaceWith`
2. **Rewrite** — Build new code/line-table arrays from the marked instructions, computing an offset mapping
3. **Fixup** — Remap all jump targets using the offset mapping

The optimizer is applied recursively to nested prototypes in constants before optimizing the parent.

### Pass 1: Dead Code After TAIL_CALL

Removes unreachable instructions after a `TAIL_CALL` up to the next jump target. Since `TAIL_CALL` never returns, any code between it and the next reachable point is dead.

```
TAIL_CALL 1
RETURN        ← removed (dead)
FUNC_RETURN   ← removed (dead)
```

### Pass 2: Redundant JUMP Removal

Removes `JUMP` instructions that target the immediately following instruction. These are generated by the compiler for certain control flow patterns (e.g., empty else branches).

```
JUMP 5        ← removed (target is next instruction)
[offset 5]
```

### Pass 3: SET_LOCAL/GET_LOCAL Pair Elimination

Detects `SET_LOCAL n; GET_LOCAL n` pairs (store then immediately reload the same slot) and optimizes them based on liveness analysis:

- **Dead slot** (slot `n` is never read again before being overwritten): remove both instructions, leaving the value on the stack
- **Live slot**: rewrite to `DUP; SET_LOCAL n` — keeps the value on the stack while also storing it

The liveness analysis is conservative: it scans forward on the straight-line path and bails out at any control flow (jumps, returns, loop constructs).

```
-- Before (dead slot):       -- Before (live slot):
SET_LOCAL 3                  SET_LOCAL 3
GET_LOCAL 3                  GET_LOCAL 3
                             ... later reads slot 3 ...
-- After (dead slot):        -- After (live slot):
(both removed, value stays   DUP
 on stack)                   SET_LOCAL 3
```

### Pass 4: Superinstructions

Fuses common two-instruction sequences into single specialized opcodes. This reduces dispatch overhead in the VM's instruction loop:

| Pattern | Superinstruction |
|---------|-----------------|
| `GET_LOCAL n; CALL k` | `GET_LOCAL_CALL(n, k)` |
| `GET_LOCAL n; TUPLE_GET i` | `GET_LOCAL_TUPLE_GET(n, i)` |
| `GET_LOCAL n; FIELD f` | `GET_LOCAL_FIELD(n, f)` |

### Pass 5: Jump Tables (currently disabled)

Detects chains of `GET_LOCAL; TAG_EQ; JUMP_IF_FALSE` (generated by match expressions on variants) and replaces them with a single `JUMP_TABLE` instruction for O(1) dispatch. Only applies when the tag range is dense (range <= 2x the number of arms).

```
-- Before:                    -- After:
GET_LOCAL 0                   GET_LOCAL 0
TAG_EQ 0                     JUMP_TABLE(min=0, [addr0, addr1, addr2], default)
JUMP_IF_FALSE next1
...
GET_LOCAL 0
TAG_EQ 1
JUMP_IF_FALSE next2
...
```

This pass is currently disabled pending investigation of an edge case.

## Future Optimization Opportunities

There are two natural insertion points for further optimization:

1. **Between 3c and 4 — typed AST optimization** (pass over tprogram/texpr). This is the richest IR since you have full type info + tree structure. Good for constant folding, dead branch elimination, match simplification, inlining simple functions, and let flattening.

2. **After 4 — additional bytecode peephole passes**. Good for jump threading, constant propagation through the stack, and push/pop cancellation.
